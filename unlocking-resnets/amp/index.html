<!DOCTYPE html>
<html ⚡>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <title>Opening Resnets</title>

    <link rel="canonical" href="https://anup-blog.netlify.app/unlocking-resnets/" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="Explorations" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Opening Resnets" />
    <meta property="og:description" content="Step by step exploration on what happens to an image in Resnets Residual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - Deep Residual Learning for Image Recognition. Resnets effectively solves the vanishing gradient" />
    <meta property="og:url" content="https://anup-blog.netlify.app/unlocking-resnets/" />
    <meta property="og:image" content="https://anup-blog.netlify.app/content/images/2021/09/resnet.png" />
    <meta property="article:published_time" content="2021-09-30T05:26:00.000Z" />
    <meta property="article:modified_time" content="2021-10-03T05:26:04.000Z" />
    <meta property="article:tag" content="Deep Learning" />
    
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Opening Resnets" />
    <meta name="twitter:description" content="Step by step exploration on what happens to an image in Resnets Residual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - Deep Residual Learning for Image Recognition. Resnets effectively solves the vanishing gradient" />
    <meta name="twitter:url" content="https://anup-blog.netlify.app/unlocking-resnets/" />
    <meta name="twitter:image" content="https://anup-blog.netlify.app/content/images/2021/09/resnet.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Anup Joseph" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Deep Learning" />
    <meta name="twitter:site" content="@ghost" />
    <meta property="og:image:width" content="1024" />
    <meta property="og:image:height" content="413" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Explorations",
        "url": "https://anup-blog.netlify.app/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://anup-blog.netlify.app/favicon.ico",
            "width": 48,
            "height": 48
        }
    },
    "author": {
        "@type": "Person",
        "name": "Anup Joseph",
        "image": {
            "@type": "ImageObject",
            "url": "https://anup-blog.netlify.app/content/images/2021/09/anup_avatar.png",
            "width": 528,
            "height": 560
        },
        "url": "https://anup-blog.netlify.app/author/anup/",
        "sameAs": []
    },
    "headline": "Opening Resnets",
    "url": "https://anup-blog.netlify.app/unlocking-resnets/",
    "datePublished": "2021-09-30T05:26:00.000Z",
    "dateModified": "2021-10-03T05:26:04.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://anup-blog.netlify.app/content/images/2021/09/resnet.png",
        "width": 1024,
        "height": 413
    },
    "keywords": "Deep Learning",
    "description": "Step by step exploration on what happens to an image in Resnets\n\nResidual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu\nZhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - \nDeep Residual Learning for Image Recognition\n[https://arxiv.org/pdf/1512.03385.pdf]. Resnets effectively solves the vanishing\ngradient problem for deep networks and the ideas they introduced have been used\nin multiple architectures from there on. \n\nIn a recent assignment I w",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://anup-blog.netlify.app/"
    }
}
    </script>

    <meta name="generator" content="Ghost 4.16" />
    <link rel="alternate" type="application/rss+xml" title="Explorations" href="https://anup-blog.netlify.app/rss/" />

    <style amp-custom>
    *,
    *::before,
    *::after {
        box-sizing: border-box;
    }

    html {
        overflow-x: hidden;
        overflow-y: scroll;
        font-size: 62.5%;
        -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
    }

    body {
        min-height: 100vh;
        margin: 0;
        padding: 0;
        color: #3a4145;
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        font-size: 1.7rem;
        line-height: 1.55em;
        font-weight: 400;
        font-style: normal;
        background: #fff;
        scroll-behavior: smooth;
        overflow-x: hidden;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    p,
    ul,
    ol,
    li,
    dl,
    dd,
    hr,
    pre,
    form,
    table,
    video,
    figure,
    figcaption,
    blockquote {
        margin: 0;
        padding: 0;
    }

    ul[class],
    ol[class] {
        padding: 0;
        list-style: none;
    }

    img {
        display: block;
        max-width: 100%;
    }

    input,
    button,
    select,
    textarea {
        font: inherit;
        -webkit-appearance: none;
    }

    fieldset {
        margin: 0;
        padding: 0;
        border: 0;
    }

    label {
        display: block;
        font-size: 0.9em;
        font-weight: 700;
    }

    hr {
        position: relative;
        display: block;
        width: 100%;
        height: 1px;
        border: 0;
        border-top: 1px solid currentcolor;
        opacity: 0.1;
    }

    ::selection {
        text-shadow: none;
        background: #cbeafb;
    }

    mark {
        background-color: #fdffb6;
    }

    small {
        font-size: 80%;
    }

    sub,
    sup {
        position: relative;
        font-size: 75%;
        line-height: 0;
        vertical-align: baseline;
    }
    sup {
        top: -0.5em;
    }
    sub {
        bottom: -0.25em;
    }

    ul li + li {
        margin-top: 0.6em;
    }

    a {
        color: var(--ghost-accent-color, #1292EE);
        text-decoration-skip-ink: auto;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 0;
        font-weight: 700;
        color: #121212;
        line-height: 1.4em;
    }

    h1 {
        font-size: 3.4rem;
        line-height: 1.1em;
    }

    h2 {
        font-size: 2.4rem;
        line-height: 1.2em;
    }

    h3 {
        font-size: 1.8rem;
    }

    h4 {
        font-size: 1.7rem;
    }

    h5 {
        font-size: 1.6rem;
    }

    h6 {
        font-size: 1.6rem;
    }

    amp-img {
        height: 100%;
        width: 100%;
        max-width: 100%;
        max-height: 100%;
    }

    amp-img img {
        object-fit: cover;
    }

    .page-header {
        padding: 50px 5vmin 30px;
        text-align: center;
        font-size: 2rem;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }

    .page-header a {
        color: #121212;
        font-weight: 700;
        text-decoration: none;
        font-size: 1.6rem;
        letter-spacing: -0.1px;
    }

    .post {
        max-width: 680px;
        margin: 0 auto;
    }

    .post-header {
        margin: 0 5vmin 5vmin;
        text-align: center;
    }

    .post-meta {
        margin: 1rem 0 0 0;
        text-transform: uppercase;
        color: #738a94;
        font-weight: 500;
        font-size: 1.3rem;
    }

    .post-image {
        margin: 0 0 5vmin;
    }

    .post-image img {
        display: block;
        width: 100%;
        height: auto;
    }

    .post-content {
        padding: 0 5vmin;
    }

    .post-content > * + * {
        margin-top: 1.5em;
    }

    .post-content [id]:not(:first-child) {
        margin: 2em 0 0;
    }

    .post-content > [id] + * {
        margin-top: 1rem;
    }

    .post-content [id] + .kg-card,
    .post-content blockquote + .kg-card {
        margin-top: 40px;
    }

    .post-content > ul,
    .post-content > ol,
    .post-content > dl {
        padding-left: 1.9em;
    }

    .post-content hr {
        margin-top: 40px;
    }

    .post .post-content hr + * {
        margin-top: 40px;
    }

    .post-content amp-img {
        background-color: #f8f8f8;
    }

    .post-content blockquote {
        position: relative;
        font-style: italic;
    }

    .post-content blockquote::before {
        content: "";
        position: absolute;
        left: -1.5em;
        top: 0;
        bottom: 0;
        width: 0.3rem;
        background: var(--ghost-accent-color, #1292EE);
    }

    .post-content :not(.kg-card):not([id]) + .kg-card {
        margin-top: 40px;
    }

    .post-content .kg-card + :not(.kg-card) {
        margin-top: 40px;
    }

    .kg-card figcaption {
        padding: 1.5rem 1.5rem 0;
        text-align: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.4em;
        opacity: 0.6;
    }

    .kg-card figcaption strong {
        color: rgba(0,0,0,0.8);
    }

    .post-content :not(pre) code {
        vertical-align: middle;
        padding: 0.15em 0.4em 0.15em;
        border: #e1eaef 1px solid;
        font-weight: 400;
        font-size: 0.9em;
        line-height: 1em;
        color: #15171a;
        background: #f0f6f9;
        border-radius: 0.25em;
    }

    .post-content > pre {
        overflow: scroll;
        padding: 16px 20px;
        color: #fff;
        background: #1F2428;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0,0,0,.1), 0 0 1px rgba(0,0,0,.4);
    }

    .kg-embed-card {
        display: flex;
        flex-direction: column;
        align-items: center;
        width: 100%;
    }

    .kg-image-card img {
        margin: auto;
    }

    .kg-gallery-card + .kg-gallery-card {
        margin-top: 0.75em;
    }

    .kg-gallery-container {
        position: relative;
    }

    .kg-gallery-row {
        display: flex;
        flex-direction: row;
        justify-content: center;
    }

    .kg-gallery-image {
        width: 100%;
        height: 100%;
    }

    .kg-gallery-row:not(:first-of-type) {
        margin: 0.75em 0 0 0;
    }

    .kg-gallery-image:not(:first-of-type) {
        margin: 0 0 0 0.75em;
    }

    .kg-bookmark-card,
    .kg-bookmark-publisher {
        position: relative;
    }

    .kg-bookmark-container,
    .kg-bookmark-container:hover {
        display: flex;
        flex-wrap: wrap;
        flex-direction: row-reverse;
        color: currentColor;
        background: rgba(255,255,255,0.6);
        font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Open Sans,Helvetica Neue,sans-serif;
        text-decoration: none;
        border-radius: 5px;
        box-shadow: 0 2px 6px -2px rgba(0, 0, 0, 0.1), 0 0 1px rgba(0, 0, 0, 0.4);
        overflow: hidden;
    }

    .kg-bookmark-content {
        flex-basis: 0;
        flex-grow: 999;
        padding: 20px;
        order: 1;
    }

    .kg-bookmark-title {
        font-weight: 600;
        font-size: 1.5rem;
        line-height: 1.3em;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        max-height: 45px;
        margin: 0.5em 0 0 0;
        font-size: 1.4rem;
        line-height: 1.55em;
        overflow: hidden;
        opacity: 0.8;
        -webkit-line-clamp: 2;
        -webkit-box-orient: vertical;
    }

    .kg-bookmark-metadata {
        margin-top: 20px;
    }

    .kg-bookmark-metadata {
        display: flex;
        align-items: center;
        font-weight: 500;
        font-size: 1.3rem;
        line-height: 1.3em;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
    }

    .kg-bookmark-description {
        display: -webkit-box;
        -webkit-box-orient: vertical;
        -webkit-line-clamp: 2;
        overflow: hidden;
    }

    .kg-bookmark-metadata amp-img {
        width: 18px;
        height: 18px;
        max-width: 18px;
        max-height: 18px;
        margin-right: 10px;
    }

    .kg-bookmark-thumbnail {
        display: flex;
        flex-basis: 20rem;
        flex-grow: 1;
        justify-content: flex-end;
    }

    .kg-bookmark-thumbnail amp-img {
        max-height: 200px;
    }

    .kg-bookmark-author {
        white-space: nowrap;
        text-overflow: ellipsis;
        overflow: hidden;
    }

    .kg-bookmark-publisher::before {
        content: "•";
        margin: 0 .5em;
    }

    .kg-width-full.kg-card-hascaption {
        display: grid;
        grid-template-columns: inherit;
    }

    .post-content table {
        border-collapse: collapse;
        width: 100%;
    }

    .post-content th {
        padding: 0.5em 0.8em;
        text-align: left;
        font-size: .75em;
        text-transform: uppercase;
    }

    .post-content td {
        padding: 0.4em 0.7em;
    }

    .post-content tbody tr:nth-child(2n + 1) {
        background-color: rgba(0,0,0,0.1);
        padding: 1px;
    }

    .post-content tbody tr:nth-child(2n + 2) td:last-child {
        box-shadow:
            inset 1px 0 rgba(0,0,0,0.1),
            inset -1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:nth-child(2n + 2) td {
        box-shadow: inset 1px 0 rgba(0,0,0,0.1);
    }

    .post-content tbody tr:last-child {
        border-bottom: 1px solid rgba(0,0,0,.1);
    }

    .page-footer {
        padding: 60px 5vmin;
        margin: 60px auto 0;
        text-align: center;
        background-color: #f8f8f8;
    }

    .page-footer h3 {
        margin: 0.5rem 0 0 0;
    }

    .page-footer p {
        max-width: 500px;
        margin: 1rem auto 1.5rem;
        font-size: 1.7rem;
        line-height: 1.5em;
        color: rgba(0,0,0,0.6)
    }

    .powered {
        display: inline-flex;
        align-items: center;
        margin: 30px 0 0;
        padding: 6px 9px 6px 6px;
        border: rgba(0,0,0,0.1) 1px solid;
        font-size: 12px;
        line-height: 12px;
        letter-spacing: -0.2px;
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Fira Sans", "Droid Sans", "Helvetica Neue", sans-serif;
        font-weight: 500;
        color: #222;
        text-decoration: none;
        background: #fff;
        border-radius: 6px;
    }

    .powered svg {
        height: 16px;
        width: 16px;
        margin: 0 6px 0 0;
    }

    @media (max-width: 600px) {
        body {
            font-size: 1.6rem;
        }
        h1 {
            font-size: 3rem;
        }

        h2 {
            font-size: 2.2rem;
        }
    }

    @media (max-width: 400px) {
        h1 {
            font-size: 2.6rem;
            line-height: 1.15em;
        }
        h2 {
            font-size: 2rem;
            line-height: 1.2em;
        }
        h3 {
            font-size: 1.7rem;
        }
    }

    :root {--ghost-accent-color: #13ae63;}
    </style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    

</head>

<body class="amp-template">
    <header class="page-header">
        <a href="https://anup-blog.netlify.app">
                Explorations
        </a>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Opening Resnets</h1>
                <section class="post-meta">
                    Anup Joseph -
                    <time class="post-date" datetime="2021-09-30">30 Sep 2021</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://anup-blog.netlify.app/content/images/2021/09/resnet.png" width="600" height="340" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <p><strong><em>Step by step exploration on what happens to an image in Resnets</em></strong></p><p>Residual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - <a href="https://arxiv.org/pdf/1512.03385.pdf">Deep Residual Learning for Image Recognition</a>. Resnets effectively solves the vanishing gradient problem for deep networks and the ideas they introduced have been used in multiple architectures from there on. </p><p>In a recent assignment I was tasked with understanding how Resnets worked and present the same. I was curious to know what actually happened to an image in Resnet and tried to work out the same. This blog post is the result of that experiment and tries to illustrate the various calculations that happen inside the Resnet architecture.</p><p><em>Before we begin, I am almost certain that this article will have mistakes. I have tried my best to eliminate them. However if you do find any mistake please let me know in the comment or mail personally <a href="mailto:anup20joseph@gmail.com">here</a> and I will fix them as soon as possible.</em></p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><figcaption>Resnet architectures</figcaption></figure><p>The Resnet paper,  quite helpfully provides this diagram dividing the network into blocks and showing the output sizes of each block. However this picture might give idea that stride is common through the network from block 2 to 5, which is not the case. We also need to look at the Resnet 34 network given in the paper.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Resnet 34 architecture with residual connections</figcaption></figure><p>This image adds crucial information about strides missing in the earlier image. However this does not have the concise block structures of the earlier image, so I suggest to keep them both at hand. There is one more important bit of information useful in computing the image size. The paper expresses this as </p><p><em>we use identity mapping for all shortcuts and zero-padding for increasing dimensions.</em></p><p>However, I feel that this bit of Python in the (old)Tensorflow implementation of Resnet is a bit more helpful.</p><pre><code class="language-python">padding=('SAME' if strides == 1 else 'VALID')</code></pre><p>This acts as a nice rule for computing through the architecture after block 1 without having to think it through every time. For people wondering what is <em>padding="SAME" </em>and <em>padding="VALID" </em>try this <a href="https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t">link</a>. Armed with all that info, lets get to work.</p><p>Input image size - (224,224,3)</p><h3 id="block-1-conv1">Block 1: conv1</h3><p>Layer 1: Convolution(filters=64, kernel_size=7x7, strides=2)</p><p>To calculate the output size in a convolution layer we use this formula:</p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 542 80" width="542" height="80">
  
  
  <defs>
    
  </defs>
  <rect x="0" y="0" width="542" height="80" fill="#ffffff"></rect><g transform="translate(10 20) rotate(0 76.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">output_size = </text></g><g transform="translate(171 10) rotate(0 155 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">input - kernel_size + 2*padding</text></g><g stroke-linecap="round"><g transform="translate(167 35) rotate(0 158.86764805005396 0.6714253277797297)"><path d="M-0.1 0.54 C53.29 0.71, 266.12 0.33, 319.35 0.37 M-1.61 -0.23 C51.73 0.16, 265.21 1.21, 318.58 1.57" stroke="#000000" stroke-width="1" fill="none"></path></g></g><g transform="translate(504 24) rotate(0 14 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">+ 1</text></g><g transform="translate(318 45) rotate(0 28.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">stride</text></g></svg><p>For the first input the above rule does not apply instead the padding is 2.</p><p>Output size = (224 - 7 + 2 * 2) / 2 + 1 = 111.5 ≈ 112.															</p><p>Final output size of this block = (112x112x64)</p><h3 id="block-2-conv2x">Block 2: conv2_x</h3><p>Layer 1: Maxpool(kernel_size=3x3, strides=2)</p><p>To calculate the output size in a maxpool layer we use this formula</p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 407 80" width="407" height="80">
  
  
  <defs>
    
  </defs>
  <rect x="0" y="0" width="407" height="80" fill="#ffffff"></rect><g transform="translate(10 20) rotate(0 76.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">output_size = </text></g><g transform="translate(171 10) rotate(0 91.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">input - kernel_size</text></g><g stroke-linecap="round"><g transform="translate(167 35) rotate(0 96.54208162748716 0.4570427794335501)"><path d="M-0.1 0.54 C32.51 0.64, 162.25 -0.03, 194.7 -0.06 M-1.61 -0.23 C30.96 0.08, 161.33 0.85, 193.93 1.14" stroke="#000000" stroke-width="1" fill="none"></path></g></g><g transform="translate(369 24) rotate(0 14 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">+ 1</text></g><g transform="translate(218 45) rotate(0 28.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space:pre" direction="ltr">stride</text></g></svg><p>Output size = (112 - 3) / 2+ 1 = 56																				</p><p>Output size = (56x56x64)</p><p>Layer 2: Convolution(filters=64, kernel_size=3x3, strides=1)</p><p>Output size = (56 - 3 + 2 x 1 ) / 1 + 1 = 55.5 ≈ 56</p><p>Output size = (56x6x64)</p><p>There are 5 more Convolution(filters=64, kernel_size=3x3, strides=1) layers. As you can see from the above calculation this does not downsample the image and hence the output size remains the size. Hence the output from this block is (56x56x64).</p><h3 id="block-3-conv3x">Block 3: conv3_x</h3><p>Layer 1: Convolution(filters=128, kernel_size=3x3, strides=2)</p><p>Output size = (56 - 3 + 2 x 0) / 2 + 1 = 27.5 ≈ 28</p><p>Output size = (28x28x128)</p><p>Layer 2: Convolution(filters=128, kernel_size=3x3, strides=1)</p><p>Output size = (28 - 3 + 2 x 1) / 1 + 1 = 28</p><p>Output size = (28x28x128)</p><p>There are 6 more Convolution(filters=128, kernel_size=3x3, strides=1) layers. Again this does not downsample the image and hence the output size remains the size. Hence the output from this block is (28x28x128).</p><h3 id="block-4-conv4x">Block 4: conv4_x</h3><p>Layer 1: Convolution(filters=256, kernel_size=3x3, strides=2)</p><p>Output size = (28 - 3 + 2 x 0) / 2 + 1 = 13.5 ≈ 14</p><p>Output size = (14x14x256)</p><p>Layer 2: Convolution(filters=256, kernel_size=3x3, strides=1)</p><p>Output size = (14 - 3 + 2 x 1) / 1 + 1 = 14</p><p>Output size = (14x14x256)</p><p>There are 10 more Convolution(filters=256, kernel_size=3x3, strides=1) layers. And like above the output size remains the same. So final output size = (14x14x256).</p><h3 id="block-5-conv5x">Block 5: conv5_x</h3><p>Layer 1: Convolution(filters=512, kernel_size=3x3, strides=2)</p><p>Output size = (14 - 3 + 2 x 0) / 2 + 1 = 6.5 ≈ 7</p><p>Output size = (7x7x512)</p><p>Layer 2: Convolution(filters=512, kernel_size=3x3, strides=1)</p><p>Output size = (7 - 3 + 2x1)/1 +1 = 7</p><p>Output size = (7x7x512)</p><p>There are 4 more Convolution(filters=512, kernel_size=3x3, strides=1) layers. And like above the output size remains the same. So final output size = (7x7x512).</p><h3 id="block-5-conv5x-1">Block 5: conv5_x</h3><p>Global average pool is essentially a large classifier which converts the 7x7x512 layer into 1x1x1000 as the Resnet is trained on the ImageNet dataset which has a thousand classes.</p>

            </section>

        </article>
    </main>
    <footer class="page-footer">
        <h3>Explorations</h3>
            <p>Thoughts, stories, ideas and whatever other random thing came to my mind.</p>
        <p><a href="https://anup-blog.netlify.app">Read more posts →</a></p>
        <a class="powered" href="https://ghost.org" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 156 156"><g fill="none" fill-rule="evenodd"><rect fill="#15212B" width="156" height="156" rx="27"/><g transform="translate(36 36)" fill="#F6F8FA"><path d="M0 71.007A4.004 4.004 0 014 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0130 84H4a4 4 0 01-4-4.007v-8.986zM50 71.007A4.004 4.004 0 0154 67h26a4 4 0 014 4.007v8.986A4.004 4.004 0 0180 84H54a4 4 0 01-4-4.007v-8.986z"/><rect y="34" width="84" height="17" rx="4"/><path d="M0 4.007A4.007 4.007 0 014.007 0h41.986A4.003 4.003 0 0150 4.007v8.986A4.007 4.007 0 0145.993 17H4.007A4.003 4.003 0 010 12.993V4.007z"/><rect x="67" width="17" height="17" rx="4"/></g></g></svg> Published with Ghost</a>
    </footer>
    
</body>
</html>
