<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Explorations]]></title><description><![CDATA[Thoughts, stories, ideas and whatever other random thing came to my mind.]]></description><link>https://anup-blog.netlify.app/</link><image><url>https://anup-blog.netlify.app/favicon.png</url><title>Explorations</title><link>https://anup-blog.netlify.app/</link></image><generator>Ghost 4.16</generator><lastBuildDate>Thu, 30 Sep 2021 05:40:36 GMT</lastBuildDate><atom:link href="https://anup-blog.netlify.app/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Opening Resnets]]></title><description><![CDATA[<p><strong><em>Step by step exploration on what happens to an image in Resnets</em></strong></p><p>Residual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - <a href="https://arxiv.org/pdf/1512.03385.pdf">Deep Residual Learning for Image Recognition</a>. Resnets effectively solves the vanishing gradient</p>]]></description><link>https://anup-blog.netlify.app/unlocking-resnets/</link><guid isPermaLink="false">614410e54298b8193f10a668</guid><dc:creator><![CDATA[Anup Joseph]]></dc:creator><pubDate>Thu, 30 Sep 2021 05:26:00 GMT</pubDate><media:content url="https://anup-blog.netlify.app/content/images/2021/09/resnet.png" medium="image"/><content:encoded><![CDATA[<img src="https://anup-blog.netlify.app/content/images/2021/09/resnet.png" alt="Opening Resnets"><p><strong><em>Step by step exploration on what happens to an image in Resnets</em></strong></p><p>Residual Networks(Resnets from here on) were introduced by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun of Microsoft Research in their seminal paper - <a href="https://arxiv.org/pdf/1512.03385.pdf">Deep Residual Learning for Image Recognition</a>. Resnets effectively solves the vanishing gradient problem for deep networks and the ideas they introduced have been used in multiple architectures from there on. </p><p>In a recent assignment I was tasked with understanding how Resnets worked and present the same. I was curious to know what actually happened to an image in Resnet and tried to work out the same. This blog post is the result of that experiment and tries to illustrate the various calculations that happen inside the Resnet architecture.</p><p><em>Before we begin, I am almost certain that this article will have mistakes. I have tried my best to eliminate them. However if you do find any mistake please let me know in the comment or mail personally <a href="mailto:anup20joseph@gmail.com">here</a> and I will fix them as soon as possible.</em></p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="https://anup-blog.netlify.app/content/images/2021/09/network.png" class="kg-image" alt="Opening Resnets" loading="lazy" width="614" height="276" srcset="https://anup-blog.netlify.app/content/images/size/w600/2021/09/network.png 600w, https://anup-blog.netlify.app/content/images/2021/09/network.png 614w"><figcaption>Resnet architectures</figcaption></figure><p>The Resnet paper, &#xA0;quite helpfully provides this diagram dividing the network into blocks and showing the output sizes of each block. However this picture might give idea that stride is common through the network from block 2 to 5, which is not the case. We also need to look at the Resnet 34 network given in the paper.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://anup-blog.netlify.app/content/images/2021/09/Architecture-Resnet-34.png" class="kg-image" alt="Opening Resnets" loading="lazy" width="86" height="539"><figcaption>Resnet 34 architecture with residual connections</figcaption></figure><p>This image adds crucial information about strides missing in the earlier image. However this does not have the concise block structures of the earlier image, so I suggest to keep them both at hand. There is one more important bit of information useful in computing the image size. The paper expresses this as </p><p><em>we use identity mapping for all shortcuts and zero-padding for increasing dimensions.</em></p><p>However, I feel that this bit of Python in the (old)Tensorflow implementation of Resnet is a bit more helpful.</p><pre><code class="language-python">padding=(&apos;SAME&apos; if strides == 1 else &apos;VALID&apos;)</code></pre><p>This acts as a nice rule for computing through the architecture after block 1 without having to think it through every time. For people wondering what is <em>padding=&quot;SAME&quot; </em>and <em>padding=&quot;VALID&quot; </em>try this <a href="https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t">link</a>. Armed with all that info, lets get to work.</p><p>Input image size - (224,224,3)</p><h3 id="block-1-conv1">Block 1: conv1</h3><p>Layer 1: Convolution(filters=64, kernel_size=7x7, strides=2)</p><p>To calculate the output size in a convolution layer we use this formula:</p><!--kg-card-begin: html--><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 542 80" width="542" height="80">
  <!-- svg-source:excalidraw -->
  
  <defs>
    <style>
      @font-face {
        font-family: "Virgil";
        src: url("https://excalidraw.com/Virgil.woff2");
      }
      @font-face {
        font-family: "Cascadia";
        src: url("https://excalidraw.com/Cascadia.woff2");
      }
    </style>
  </defs>
  <rect x="0" y="0" width="542" height="80" fill="#ffffff"/><g transform="translate(10 20) rotate(0 76.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">output_size = </text></g><g transform="translate(171 10) rotate(0 155 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">input - kernel_size + 2*padding</text></g><g stroke-linecap="round"><g transform="translate(167 35) rotate(0 158.86764805005396 0.6714253277797297)"><path d="M-0.1 0.54 C53.29 0.71, 266.12 0.33, 319.35 0.37 M-1.61 -0.23 C51.73 0.16, 265.21 1.21, 318.58 1.57" stroke="#000000" stroke-width="1" fill="none"/></g></g><g transform="translate(504 24) rotate(0 14 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">+ 1</text></g><g transform="translate(318 45) rotate(0 28.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">stride</text></g></svg><!--kg-card-end: html--><p>For the first input the above rule does not apply instead the padding is 2.</p><p>Output size = (224 - 7 + 2 * 2) / 2 + 1 = 111.5 &#x2248; 112.															</p><p>Final output size of this block = (112x112x64)</p><h3 id="block-2-conv2x">Block 2: conv2_x</h3><p>Layer 1: Maxpool(kernel_size=3x3, strides=2)</p><p>To calculate the output size in a maxpool layer we use this formula</p><!--kg-card-begin: html--><svg version="1.1" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 407 80" width="407" height="80">
  <!-- svg-source:excalidraw -->
  
  <defs>
    <style>
      @font-face {
        font-family: "Virgil";
        src: url("https://excalidraw.com/Virgil.woff2");
      }
      @font-face {
        font-family: "Cascadia";
        src: url("https://excalidraw.com/Cascadia.woff2");
      }
    </style>
  </defs>
  <rect x="0" y="0" width="407" height="80" fill="#ffffff"/><g transform="translate(10 20) rotate(0 76.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">output_size = </text></g><g transform="translate(171 10) rotate(0 91.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">input - kernel_size</text></g><g stroke-linecap="round"><g transform="translate(167 35) rotate(0 96.54208162748716 0.4570427794335501)"><path d="M-0.1 0.54 C32.51 0.64, 162.25 -0.03, 194.7 -0.06 M-1.61 -0.23 C30.96 0.08, 161.33 0.85, 193.93 1.14" stroke="#000000" stroke-width="1" fill="none"/></g></g><g transform="translate(369 24) rotate(0 14 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">+ 1</text></g><g transform="translate(218 45) rotate(0 28.5 12.5)"><text x="0" y="18" font-family="Virgil, Segoe UI Emoji" font-size="20px" fill="#000000" text-anchor="start" style="white-space: pre;" direction="ltr">stride</text></g></svg><!--kg-card-end: html--><p>Output size = (112 - 3) / 2+ 1 = 56																				</p><p>Output size = (56x56x64)</p><p>Layer 2: Convolution(filters=64, kernel_size=3x3, strides=1)</p><p>Output size = (56 - 3 + 2 x 1 ) / 1 + 1 = 55.5 &#x2248; 56</p><p>Output size = (56x6x64)</p><p>There are 5 more Convolution(filters=64, kernel_size=3x3, strides=1) layers. As you can see from the above calculation this does not downsample the image and hence the output size remains the size. Hence the output from this block is (56x56x64).</p><h3 id="block-3-conv3x">Block 3: conv3_x</h3><p>Layer 1: Convolution(filters=128, kernel_size=3x3, strides=2)</p><p>Output size = (56 - 3 + 2 x 0) / 2 + 1 = 27.5 &#x2248; 28</p><p>Output size = (28x28x128)</p><p>Layer 2: Convolution(filters=128, kernel_size=3x3, strides=1)</p><p>Output size = (28 - 3 + 2 x 1) / 1 + 1 = 28</p><p>Output size = (28x28x128)</p><p>There are 6 more Convolution(filters=128, kernel_size=3x3, strides=1) layers. Again this does not downsample the image and hence the output size remains the size. Hence the output from this block is (28x28x128).</p><h3 id="block-4-conv4x">Block 4: conv4_x</h3><p>Layer 1: Convolution(filters=256, kernel_size=3x3, strides=2)</p><p>Output size = (28 - 3 + 2 x 0) / 2 + 1 = 13.5 &#x2248; 14</p><p>Output size = (14x14x256)</p><p>Layer 2: Convolution(filters=256, kernel_size=3x3, strides=1)</p><p>Output size = (14 - 3 + 2 x 1) / 1 + 1 = 14</p><p>Output size = (14x14x256)</p><p>There are 10 more Convolution(filters=256, kernel_size=3x3, strides=1) layers. And like above the output size remains the same. So final output size = (14x14x256).</p><h3 id="block-5-conv5x">Block 5: conv5_x</h3><p>Layer 1: Convolution(filters=512, kernel_size=3x3, strides=2)</p><p>Output size = (14 - 3 + 2 x 0) / 2 + 1 = 6.5 &#x2248; 7</p><p>Output size = (7x7x512)</p><p>Layer 2: Convolution(filters=512, kernel_size=3x3, strides=1)</p><p>Output size = (7 - 3 + 2x1)/1 +1 = 7</p><p>Output size = (7x7x512)</p><p>There are 4 more Convolution(filters=512, kernel_size=3x3, strides=1) layers. And like above the output size remains the same. So final output size = (7x7x512).</p><h3 id="block-5-conv5x-1">Block 5: conv5_x</h3><p>Global average pool is essentially a large classifier which converts the 7x7x512 layer into 1x1x1000 as the Resnet is trained on the ImageNet dataset which has a thousand classes.</p>]]></content:encoded></item></channel></rss>